name: Update debthin indexes

on:
  schedule:
    - cron: "0 4 * * *"   # daily index update
    - cron: "0 3 * * 0"   # weekly re-curation on Sundays
  workflow_dispatch:
    inputs:
      force_recurate:
        description: "Re-run curation from popcon"
        type: boolean
        default: false

concurrency:
  group: update-indexes
  cancel-in-progress: false

jobs:
  update:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Get week number (for cache key)
        id: week
        run: echo "week=$(date +%Y-%V)" >> $GITHUB_OUTPUT

      - name: Restore package cache
        uses: actions/cache@v4
        with:
          path: cached/
          key: packages-${{ runner.os }}-${{ steps.week.outputs.week }}
          restore-keys: packages-${{ runner.os }}-

      - name: Import GPG key
        env:
          GPG_PRIVATE_KEY: ${{ secrets.GPG_PRIVATE_KEY }}
          GPG_KEY_ID: ${{ secrets.GPG_KEY_ID }}
        run: |
          echo "$GPG_PRIVATE_KEY" | gpg --batch --import
          echo "$GPG_KEY_ID:6:" | gpg --import-ownertrust

      - name: Re-curate package list
        if: >
          github.event.inputs.force_recurate == 'true' ||
          (github.event_name == 'schedule' && github.event.schedule == '0 3 * * 0')
        run: |
          python3 scripts/curate.py \
            --suite trixie \
            --arch amd64 \
            --output curated/debian/packages.txt \
            --deps-output curated/debian/deps.txt

      - name: Combine package lists
        run: |
          sort -u curated/debian/packages.txt curated/debian/deps.txt \
            > curated/debian/all.txt
          echo "Debian packages: $(wc -l < curated/debian/all.txt)"
          cp curated/debian/all.txt curated/ubuntu/all.txt
          echo "Ubuntu packages: $(wc -l < curated/ubuntu/all.txt)"

      - name: Fetch, filter and sign indexes
        env:
          GPG_KEY_ID: ${{ secrets.GPG_KEY_ID }}
        run: |
          mkdir -p dist_output

          DEBIAN_SUITES=(forky trixie trixie-updates bookworm bookworm-updates bullseye bullseye-updates)
          UBUNTU_SUITES=(
              jammy jammy-updates jammy-backports
              noble noble-updates noble-backports
              plucky plucky-updates plucky-backports
              questing questing-updates questing-backports
          )
          DEBIAN_ARCHES=(amd64 arm64 armhf i386 riscv64)
          DEBIAN_RISCV_SUITES=(forky trixie trixie-updates)
          DEBIAN_COMPONENTS=(main contrib non-free non-free-firmware)
          UBUNTU_ARCHIVE_ARCHES=(amd64 i386)
          UBUNTU_PORTS_ARCHES=(arm64 riscv64)
          UBUNTU_COMPONENTS=(main restricted universe multiverse)
          UBUNTU_ARCHIVE="https://archive.ubuntu.com/ubuntu"
          UBUNTU_PORTS="https://ports.ubuntu.com/ubuntu-ports"

          do_fetch() {
            local distro=$1 upstream_base=$2 suite=$3 component=$4 arch=$5
            local cachedir="cached/$distro/$suite/$component/binary-$arch"
            local cachefile="$cachedir/Packages.gz"
            mkdir -p "$cachedir"

            if curl -sf --retry 3 --retry-delay 5 -z "$cachefile" -o "$cachefile" \
                "$upstream_base/dists/$suite/$component/binary-$arch/Packages.gz" 2>/dev/null; then
              :
            elif [[ ! -s "$cachefile" ]]; then
              if curl -sf --retry 3 --retry-delay 5 -o "${cachefile}.xz" \
                  "$upstream_base/dists/$suite/$component/binary-$arch/Packages.xz" 2>/dev/null; then
                xzcat "${cachefile}.xz" | gzip -1 > "$cachefile" && rm -f "${cachefile}.xz"
              else
                echo "WARNING: $distro/$suite/$component/$arch not available" >&2
              fi
            fi
          }
          export -f do_fetch

          do_fetch_inrelease() {
            local distro=$1 upstream_base=$2 suite=$3
            local cachefile="cached/$distro/$suite/InRelease"
            mkdir -p "cached/$distro/$suite"
            curl -sf --retry 3 --retry-delay 5 -z "$cachefile" -o "$cachefile" \
              "$upstream_base/dists/$suite/InRelease" 2>/dev/null || true
          }
          export -f do_fetch_inrelease

          # ── Phase 1: Fetch (parallel) ─────────────────────────────────────
          echo "Phase 1: fetching upstream indexes (parallel=8)..." >&2

          {
            for suite in "${DEBIAN_SUITES[@]}"; do
              if [[ "$suite" == "bullseye" || "$suite" == "bullseye-updates" ]]; then
                components=(main contrib non-free)
              else
                components=("${DEBIAN_COMPONENTS[@]}")
              fi
              for component in "${components[@]}"; do
                echo "debian https://deb.debian.org/debian $suite $component all"
                for arch in "${DEBIAN_ARCHES[@]}"; do
                  [[ "$arch" == "riscv64" && ! " ${DEBIAN_RISCV_SUITES[*]} " =~ " $suite " ]] && continue
                  echo "debian https://deb.debian.org/debian $suite $component $arch"
                done
              done
            done
            for suite in "${UBUNTU_SUITES[@]}"; do
              for component in "${UBUNTU_COMPONENTS[@]}"; do
                for arch in "${UBUNTU_ARCHIVE_ARCHES[@]}"; do
                  echo "ubuntu $UBUNTU_ARCHIVE $suite $component $arch"
                done
                for arch in "${UBUNTU_PORTS_ARCHES[@]}"; do
                  echo "ubuntu $UBUNTU_PORTS $suite $component $arch"
                done
              done
            done
          } | xargs -P 8 -L1 bash -c 'do_fetch $@' _

          {
            for suite in "${DEBIAN_SUITES[@]}"; do
              echo "debian https://deb.debian.org/debian $suite"
            done
            for suite in "${UBUNTU_SUITES[@]}"; do
              echo "ubuntu $UBUNTU_ARCHIVE $suite"
            done
          } | xargs -P 8 -L1 bash -c 'do_fetch_inrelease $@' _

          # ── Phase 2: Batch filter ─────────────────────────────────────────
          echo "Phase 2: filtering..." >&2

          run_filter_batch() {
            local distro=$1
            local jobfile
            jobfile=$(mktemp)
            while IFS= read -r -d "" cachefile; do
              local outfile="${cachefile/cached\/$distro\//dist_output\/$distro\/dists\/}"
              mkdir -p "$(dirname "$outfile")"
              printf "%s\t%s\n" "$cachefile" "$outfile"
            done < <(find "cached/$distro" -name "Packages.gz" -print0 2>/dev/null | sort -z) > "$jobfile"
            local n; n=$(wc -l < "$jobfile")
            echo "  Filtering $distro: $n jobs..." >&2
            python3 scripts/filter.py \
              --allowed "curated/$distro/all.txt" \
              --batch "$jobfile" \
              --stats
            rm -f "$jobfile"
          }

          run_filter_batch debian
          run_filter_batch ubuntu

          # ── Phase 3: Sign (all suites, one GPG session) ──────────────────
          echo "Phase 3: signing..." >&2

          GPG_KEY_ID=$GPG_KEY_ID bash scripts/sign_all.sh \
            dist_output \
            "https://deb.debian.org/debian" \
            "$UBUNTU_ARCHIVE"

          cp index.html dist_output/
          cp debthin-keyring.gpg dist_output/
          cp debthin-keyring-binary.gpg dist_output/

      - name: Install boto3
        run: pip install boto3 --break-system-packages

      - name: Upload to R2
        env:
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_ACCESS_KEY: ${{ secrets.R2_ACCESS_KEY }}
          R2_SECRET_KEY: ${{ secrets.R2_SECRET_KEY }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
        run: |
          python3 scripts/r2_upload.py \
            --dir dist_output \
            --account "$R2_ACCOUNT_ID" \
            --access-key "$R2_ACCESS_KEY" \
            --secret-key "$R2_SECRET_KEY" \
            --bucket "$R2_BUCKET"
